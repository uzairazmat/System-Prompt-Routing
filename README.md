# System-Prompt-Routing

# ğŸ¤– System Prompt Routing (Beginner)

## ğŸ“Œ Business Problem
When building multi-capability AI apps (e.g., apps that can **write code, summarize videos, or answer legal questions**), the prompts you send to the LLM often need to change depending on the userâ€™s query.  

Instead of **manually switching prompts**, a **System Prompt Router** automatically finds and selects the best system prompt for the query using semantic similarity.

This project demonstrates how to build a simple but effective **System Prompt Router** from scratch.

---

## ğŸ› ï¸ Key Steps

1. ğŸ“š **Create a prompt library**  
   - Store prompts in a Python dictionary with descriptive keys.  

2. ğŸ” **Embed system prompts**  
   - Use [sentence-transformers](https://www.sbert.net/) to embed prompt descriptions.  

3. ğŸ’¬ **Handle user queries**  
   - Embed the incoming user query using the same model.  

4. ğŸ“Š **Find best match**  
   - Compare embeddings with [FAISS](https://faiss.ai/) for efficient similarity search.  
   - Select the system prompt with the **highest similarity score**.

---

## âš™ï¸ Tech Stack

- **[FAISS](https://faiss.ai/)** â†’ For fast similarity search.  
- **[Sentence-Transformers](https://www.sbert.net/)** â†’ For generating embeddings.  
- **[FastAPI](https://fastapi.tiangolo.com/)** â†’ Backend API for handling queries.  
- **[Streamlit](https://streamlit.io/)** â†’ Frontend UI for user interaction.  
- **[Docker](https://www.docker.com/)** â†’ To containerize and run the entire project seamlessly.  

---

## ğŸ“‚ Project Structure
System-Prompt-Routing/
â”‚â”€â”€ backend_fastapi.py # FastAPI backend logic
â”‚â”€â”€ app.py # Streamlit frontend UI
â”‚â”€â”€ build_faiss.py # Script to build FAISS index
â”‚â”€â”€ prompt_meta.pkl # Stored prompt metadata
â”‚â”€â”€ prompt_index.faiss # FAISS index file
â”‚â”€â”€ requirements.txt # Python dependencies
â”‚â”€â”€ Dockerfile.backend # Dockerfile for backend
â”‚â”€â”€ Dockerfile.frontend # Dockerfile for frontend
â”‚â”€â”€ docker-compose.yml # Compose to run multi-container setup
â””â”€â”€ README.md # Project documentation


---

## ğŸš€ How It Works

1. User enters a **query** in the Streamlit UI.  
2. The frontend calls the FastAPI backend (`/route_prompt`).  
3. Backend computes embeddings and performs **nearest-neighbor search with FAISS**.  
4. The **best matching system prompt** is returned and displayed with similarity score.  

---

## ğŸ³ Running with Docker

Build and run using Docker Compose:

``
# Build images and start containers
docker compose up --build -d

# Stop containers
docker compose down


#Example Output
User Query: "Can you assist me in writing Python code?"
âœ… Best Match: "Code Assistant"
System Prompt: "You are an expert Python assistant..."
Score: 0.8932









